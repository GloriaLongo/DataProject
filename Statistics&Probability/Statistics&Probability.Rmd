---
title: "Foundations of Probability and Statistics Project"
author: "Longo Gloria"
date: "17/11/2022"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

**Introduction**


In this project the data contained in the 'Exams' dataset (available on the website: https://www.kaggle.com/datasets/whenamancodes/students-performance-in-exams) will be analyzed through statistical analysis to reach concrete conclusions.
This dataset consists of the marks secured by the students in various subjects and some of their sociological characteristics .
the goal is to perform analyzes on the variables and try to build a linear prediction model for the school grades of future students with only the knowledge of some variables



**Description of the dataset**

The first thing to do is to load the dataset and analyze its structure


```{r}
exams<-read.csv('C:/Users/glori/OneDrive/Desktop/exams.csv')
dim(exams)
```
The 'Exams' dataset has 1000 rows and 8 columns


```{r}
colnames(exams)
str(exams)

```
The columns name are: 

 1. Gender: variable indicating the gender of the student
(Male or Female)
 
 2. race.ethnicity: variable indicating the race of the students
(Group A, Group B, Group C, Group D or Group E)
 
 3. Parental.level.of.education: variable indicating the level of education of the parents
(Some High School, Some College, Master's degree, High School, Bachelor's Degree, Associate's Degree)
 
 4. lunch: variable that indicates whether the student is entitled to a scholarship for the canteen or not (Free/Reduced, Standard)
 
 5. test.preparation.course: variable that indicates whether the student has taken the preparatory test before taking the exams (None, Completed)

 6. math.score: math exam score (integer between 1 and 100)
 
 7. reading.score: reading exam score (integer between 1 and 100)
 
 8. writing.score: writing exam score (integer between 1 and 100)
 

To get an idea of the structure of the dataset, the first six rows will be shown


```{r}
head (exams)
```

Check for the presence of null values

```{r}
sum(is.na(exams))
```

 
**Frequency distribution analysis**

Now some analysis of frequencies distribution will be carried out to understand how the observations are distributed within the variables


```{r}
gender<-exams$gender
xtabs(~ gender)
```

There are 516 Males and 483 Females (51,6% Male and 48,3% Female) therefore the sample is almost equally distributed between males and females


```{r}
race<-exams$race.ethnicity
xtabs(~ race)
```

There are 79 students in Group A, 205 in Group B, 323 in Group C, 262 in Group D and 131 in Group E. 
We will use the Gini index to see if the observations are more heterogeneously or homogeneously distributed among the various ethnicities.

```{r}
gini<- function (x)
  {freq_rel<- x/sum(x)
  gini<-1-sum(freq_rel^2)
  gini_norm<-gini*length(x)/(length(x)-1)
  return(gini_norm)
  }
tab<-xtabs(~ race)
v<-c(79, 205, 323,262,131)
round(gini(v),2)

```
The normalized Gini index is equal to 0.95, therefore it is very close to 1; this means that we are very close to maximum mutability


We will now create a double-entry table to see the distribution between ethnicities and genders


```{r}
t<-table(race, gender)
t/1000*100
```

We can observe that the largest female and male ethnic group is group C while the smallest is group A, moreover the only ethnic group in which there are more females than males is group B.



Through a while loop the percentage of sufficient votes (score > 50) obtained by the sample is then calculated


```{r}
i=1
suffmath=0
suffwri=0
suffread=0
while(i<1000){
  if(exams[i, "math.score"]>50) {suffmath=suffmath+1}
  if (exams[i, "writing.score"]>50) {suffwri=suffwri+1}
  if (exams[i, "reading.score"]>50 )  {suffread=suffread+1}
  i=i+1
}
suffmath
suffread
suffwri
```
844 (84,4%) of the students are sufficient in the math test, 886 (86,6%) are sufficient in the reading test and 848 (84,8%) are sufficient in the writing test. From the statistical results it can be seen that most of the students did not fail the exams, but the percentage of pass marks in mathematics is lower than in the other two exams.
We can then consider the dataset as an observed sample of data and construct a confidence interval for the percentage of passing grades in mathematics.
We fix a confidence level equal to 95% (alpha=0.05) and we transform the Math.score variable into a Bernullian variable which assumes the value of 1 if the observation is greater than 50 (pass grade) and zero otherwise. Finally, we consider theta as the ratio between the number of sufficient votes and total observations (1000)


```{r}
suf<-suffmath
insuf<-1000-suffmath
theta<-suf/1000
var_theta<-theta*(1-theta)
alpha<-0.05
Z<-qnorm(1-alpha/2)
IC<-c(theta -Z*sqrt(var_theta/1000),theta +Z*sqrt(var_theta/1000)) 
IC
```
Therefore with 95% confidence we can say that the proportion of individuals who pass the math test in the school is between 0.82 and 0.86

Let's now set a score threshold equal to 80 above which individuals are considered excellent.
Therefore we can consider that the school is considered among the best in the country if the arithmetic average of the mathematics marks obtained by the students exceeds 80.
We can consider the following system of hypotheses:

- H0: theta = 0.8

- H1: theta > 0.8

with theta percentage of grades in mathematics above 80. Then do a test to see if the school in question can be considered among the excellent ones starting from the sample of observations given.

```{r}
theta0<-0.8

test_statistic<- (theta-theta0)/sqrt(theta0*(1-theta0)/1000)
Z<-qnorm(1-alpha/2)
-Z<test_statistic  #True
test_statistic>Z #True

theta>theta0+(Z*sqrt(var_theta/1000)) #True
```
The null hypothesis is rejected with a confidence of 95% and therefore the school can be considered among the excellences.


We now want to verify if the excellent students are correlated with their race of origin, to do this we will first build a contingency table of the two variables.

```{r}
math_boolean<-ifelse(exams$math.score>80, "Excellent" , "NotExcellet")
table_raceMath<- table(race, math_boolean)
table_raceMath
#summary(table_raceMath)
```
We then verify, using the Chi-square test, that the two variables are independent of each other.
The Chi-square test for the independence of variables is composed of the following set of hypotheses:

- H0: there is indipendence between the two variables (expected frequencies coincide with the observed frequencies)

- H1: There isn't indipendence between the two variables

```{r}
summary(table_raceMath)
```
Since our p-value is close to zero, we reject the null hypothesis with a confidence level of 95% (alpha=0,05) so there is a dependency between the variables.


**Descriptive analyzes**

We continue with the development of some descriptive analyzes of the quantitative output variables.
We start by calculating the mean and the variance.


```{r}
math<-exams$math.score
reading<-exams$reading.score
writing<-exams$writing.score

mean(math)
mean(reading)
mean(writing)
```

The average math test score obtained from the students is 66,4 , the average for the reading test is 69 and for the writing test is 67,74


```{r}

median(math)
median(reading)
median(writing)
```

The median fo the math test score obtained from the students is 66,5 , the median for the reading test is 70 and for the writing test is 68.

Therefore both the mean and the median tell us that the most difficult exam for students is the math exam while the one they do best in is the reading one.


Now we will do some more in-depth analyzes on the Math.score variable.
The first thing we will do is group the observations into classes with the Sturges method and draw them in a graph to observe the distribution.


```{r}
nclass<- nclass.Sturges(exams$math.score)
hist(exams$math.score, breaks = nclass, main = 'Math Grades Histogram', xlab= 'Score', ylab='Frequency' )
abline()
```

We can observe that the class between the grade 60 and 70 has higher absolute frequencies in agreement with the descriptive analyzes (mean and median) carried out previously.
The distribution seems to be characterized by a slight negative asymmetry.

Now we check if the Math.score variable has an approximately Gaussian distribution

```{r}
#library("car")

qqnorm(exams$math.score)
grid()               
qqline(exams$math.score, 
       lwd = 2,      
       col = "red"   
       )

```

The graph appears to show a Gaussian distribution for the Math.score variable

Let us now proceed with the analysis of the outliers.

```{r}
par(mfrow = c(1,3))
boxplot(exams$math.score)
boxplot(exams$reading.score)
boxplot(exams$writing.score)

```
```{r}
boxplot.stats(exams$math.score)$out
boxplot.stats(exams$reading.score)$out
boxplot.stats(exams$writing.score)$out

```

The outlier values for the Math.score are: 23, 13, 13

The outlier values for the Reading.score are: 28, 29, 27, 28, 31, 29

The outlier values for the Writing.score are: 24, 23, 26, 23

These values could leverage or influence a future forecasting model based on this data so we should consider deleting them from the model.


```{r}
boxplot.stats(exams$math.score)$out
boxplot.stats(exams$reading.score)$out
boxplot.stats(exams$writing.score)$out

```


**Correlation Analysis**

We continue with the analysis of the correlation between the quantitative output variables

```{r}
cov(exams[6:8])
cor(exams[6:8])
pairs(exams[6:8])
```


As we could have imagined, the correlation between the output variables is positive and very high. This means that the student who got high marks in one exam also got them in the others.

**  Multivariate Linear Model**

Finally we build a multivariate linear model with the Math.score as dependent variable.

The parental.level.of.education column was eliminated because it was not considered significant for the estimation of the model, all the other variables instead were used and converted into quantitative.


```{r}
newdata<-exams[, c(1,2,4,5,6,7,8)]
newdata$gender<-ifelse(newdata$gender=="female",1,0)
newdata$race.ethnicity.a<-ifelse(newdata$race.ethnicity=='group A',1,0)
newdata$race.ethnicity.b<-ifelse(newdata$race.ethnicity=='group B',1,0)
newdata$race.ethnicity.c<-ifelse(newdata$race.ethnicity=='group C',1,0)
newdata$race.ethnicity.d<-ifelse(newdata$race.ethnicity=='group D',1,0)
newdata$lunch<-ifelse(newdata$lunch=="standard",1,0)
newdata$test.preparation.course<-ifelse(newdata$test.preparation.course=="completed",1,0)

mod<-lm(math.score~ gender +race.ethnicity.a + race.ethnicity.b + race.ethnicity.c + race.ethnicity.d+ test.preparation.course+ lunch, data = newdata)
anova(mod)

```
As we can see from the anova table, the chosen coefficients are significant


```{r}
summary(mod)
```

The regression coefficients are to be interpreted as follows:
for example the Gender -6,017 means that, with all the other variables being equal, the mathematics mark decreases by 6.017 points if the subject is female.

The adjusted R-squared is equal to 0,27 this means that the model explains 27% of the data. Probably the output variable in question depends on many other factors that are not present in our dataset or that are difficult to quantify.

The p-value of the F statistic instead is very close to 0, this means that we can reject the null hypothesis at a 99% confidence level according to which all the regression coefficients are equal to 0 and the model is composed only of the intercept

We now compare the values predicted by the model with the actual values


```{r}
prev<-predict(mod,type="response")
prev[0:10]-newdata$math.score[0:10]
```

**Conclusions**

In this project, a multinomial linear model has been built that is able to predict students' grades in the mathematics exam, knowing only a few variables.
The result is certainly to be improved but still a good starting point.
A future development could be to expand the dataset with other variables such as students' participation in lessons and the school they have previously attended




